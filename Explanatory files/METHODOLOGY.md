Επεξήγηση του Attica_fires.ipynb

Χρησιμοποιήθηκαν οι συλλογές δεδομένων από τον σύνδεσμο https://www.fireservice.gr/el/synola-dedomenon οι οποίες αντιστοιχούν στα έτη 2000 εως και 2021.

Η βιβλιοθήκη requests χρησιμοποιήθηκε έτσι ώστε να ληφθεί και να αποθηκευτή ο κώδικας html του παραπάνω συνδέσμου 

Η βιβλιοθήκη bs4 χρησιμοποιήθηκε έτσι ώστε να παρθούν τα ανάλογα σύνολα δεδομένων μέσω web scrabing.

Η βιβλιοθήκη urllib3 χρησιμοποιήθηκε για να απενεργοποιηθούν κάποιες προειδοποιήσεις της ιστοσελίδας η οποία εμπόδιζε την λήψη των δεδομένων.

Η βιβλιοθήκη pandas χρησιμοποιήθηκε έτσι ώστε να δημιουργηθούν dataframes να πραγματοποιηθεί επεξεργασία και να αποθηκευτούν.

Η βιβλιοθήκη re χρησιμοποιήθηκε έτσι ώστε μέσω κανονικών εκφράσεων να βρεθούν διάφορα στοιχεία στην ιστοσελίδα, όπως π.χ. οι ημερομηνίες.

Η βιβλιοθήκη time χρησιμοποιήθηκε έτσι ώστε να καθυστερήσει τα requests που στέλνονται στον server της ιστοσελίδας με σκοπό την αποφυγή υπερφόρτωσης του.

Η βιβλιοθήκη numpy χρησιμοποιήθηκε για μαθηματικές πράξεις μεταξύ των δεδομένων 

Αρχικά χρησιμοποιείται η βιβλιοθήκη requests έτσι ώστε να ληφθεί ο html κώδικας της σελίδας. Έπειτα ο κώδικας αυτός αναλύεται χρησιμοποιώντας την βιβλιοθήκη BeautifulSoup. 

Σκοπός είναι να ληφθούν μόνο τα δεδομένα των δασικών πυρκαγιών που συνέβησαν στην Ελλάδα μεταξύ των χρόνων 2000 εως και 2021. Παρατηρείται ότι οι σύνδεσμοι που θέλουμε να λάβουμε από την ιστοσελίδα που αναλύσαμε με την bs4 είναι στοιχεία  τύπου "span" της html και όλοι περιλαμβάνουν κείμενο της μορφής "Δασικές Πυρκαγιές <<Έτη>> " όπου τα έτη έχουν την μορφή xxxx ή xxxx-xxxx όπου x αριθμός. Συνεπώς για να βρεθούν οι σύνδεσμοι αυτοί μέσω του κώδικα είναι λογικό να χρησιμοποιηθούν κανονικές εκφράσεις.

Δημιουργείται ένα μοτίβο της μορφής "Δασικές Πυρκαγιές <<έτος και, άν υπάρχει, δεύτερο έτος>>"
και άλλο ένα μοτίβο της μορφής <<έτος και, άν υπάρχει, δεύτερο έτος>>

Το πρώτο μοτίβο θα χρησιμοποιηθεί έτσι ώστε να βρεθούν οι σύνδεσμοι και το δεύτερο μοτίβο θα χρησιμοποιηθεί έτσι ώστε να ονομαστούν τα αρχεία που θα ληφθούν από τους συνδέσμους.

χρησιμοποιώντας την find_all της bs4 βρίσκουμε όλα τα στοιχεία html τύπου span της ιστοσελίδας. έπειτα αποθηκεύουμε τα κείμενα αυτών των spans στην λίστα texts 

Στην συνέχεια χρησιμοποιώντας το πρώτο μοτίβο ψάχνουμε να βρούμε ποία κείμενα από την λίστα texts ταιριάζουν και αποθηκεύουμε τον δείκτη τους στην λίστα idxs

Έπειτα αποθηκεύουμε στην λίστα wanted_span, τα στοιχεία της λίστας span που αντιστοιχούν στους δείκτες που βρήκαμε παραπάνω

Τώρα έχουμε τα spans με τους συνδέσμους που θέλουμε.
Δημιουργούμε από τώρα τα όνοματα τα οποία θα έχουν τα αρχεία που θα ληφθούν. Τα ονόματα αυτά θα αποτελούνται από τα έτη που συνέβησαν οι πυρκαγιές. 

Κάθε span από την λίστα wanted_spans έχει κείμενο του τύπου "Δασικές Πυρκαγιές ετος <<και αν υπαρχει>> ετος"
αποθηκεύουμε τα κείμενα στην λίστα wanted_texts και χρησιμοποιώντας το δεύτερο μοτίβο κανονικών εκφράσεων που δημιουργήσαμε, βρίσκουμε τις συμβολοσειρές αριθμών με τα έτη και τις αποθηκεύουμε στην λίστα filenames.

Τα span στοιχεία στην λίστα wanted_spans περιέχουν στοιχεία a της html τα οποία με την σειρά τους περιέχουν την παράμετρο href στην οποία έχουν αποθηκευτεί οι σύνδεσμοι με τα σύνολα δεδομένων που θέλουμε. Τα σύνολα δεδομένων έχουν μορφή xls ή xlsx, έμεις θα χρησιμοποιήσουμε την μορφή xlsx. 

Χρησιμοποιώντας την find_all της bs4 βρίσκουμε όλα τα στοιχεία a μέσα στα span της λίστας wanted_span στην συνέχεια λαμβάνουμε την παράμετρο href από αυτά τα στοιχεία χρησιμοποιώντας συμβολισμό λεξικού της python. Αυτό μας επιστρέφει μία λίστα που περιέχει τον σύνδεσμο xls ως πρώτο στοιχείο και τον σύνδεσμο xlsx ως δεύτερο στοιχείο. Επιλέχουμε το δεύτερο στοιχείο εισάγωντας την μονάδα στα brackets. Έτσι αποθηκεύουμε τουσ συνδέσμους που θέλουμε στην λίστα xlsx_urls

Από ότι φαίνεται πήραμε δύο φορές κάποιους από τους συνδέσμους που θέλαμε. Για να μήν κάνει διπλή δουλειά το πρόγραμμα μας αφαιρούμε τις επαναλήψεις των στοιχείων μετατρέποντας σε λεξικό και πάλι πίσω σε λίστα την λίστα xlsx_urls 

Παρατηρείται ότι οι σύνδεσμοι της λίστας xlsx_urls δεν έχουν την βάση του site που είναι 'https://www.fireservice.gr/'. αποθηκεύεται σε string και τους προστίθεται χρησιμοποιώντας έναν βρόγχο.

Τώρα έχουμε κάνει την προεργασία έτσι ώστε να είμαστε έτοιμοι να κατεβάσουμε τα δεδομένα. 
αρχικοποιούμε έναν μετρητή ο οποίος μας βοηθάει να τρέξουμε τα ονόματα στην λίστα filenames έτσι ώστε να σωθούν τα αρχεία
Χρησιμοποιούμε έναν βρόγχο ο οποίος διατρέχει τους συνδέσμους της λίστας xlsx_urls
χρησιμοποιώντας την βιβλιοθήκη time περιμένουμε 2 δευτερόλεπτα μέχρι να παραλάβουμε κάθε αρχείο για να μην υπερφορτωθεί ο server με requests. Έπειτα με την requests παίρνουμε το αρχείο. 
Δημιουργούμε αρχείο xlsx στον υπολογιστή μας με το όνομα που βρίσκεται στην θέση c της λίστας filenames και για να γράψουμε σε αυτό το ανοίγουμε με binary mode ('wb')
Στην συνέχεια προσθέτουμε ένα στον μετρήτη c , γράφουμε τα περιεχόμενα των δεδομένων στο αρχείο και τέλος κλείνουμε το αρχείο.

Μέσω του βρόγχου αυτή η διαδικασία επαναλαμβάνεται για κάθε αρχείο από το 2000 μέχρι και το 2021.

Ανοίγοντας τα δεδομένα με την pandas παρατηρείται ότι τα ονόματα των στηλών βρίσκονται στην δεύτερη γραμμή του dataset και όχι στην πρώτη. 

Για να το διορθώσουμε δημιουργούμε μία συνάρτηη η οποία κατασκευάζει ένα λεξικό με κλειδιά τα παλιά ονόματα (τα ονόματα στην πρώτη γραμμή) και με values τα καινούργια ονόματα (τα ονόματα στην δεύτερη γραμμή) 
στην συνέχεια, χρησιμοποιώντας την rename της pandas αλλάζουμε τα ονόματα και τέλος πετάμε την πρώτη γραμμή έτσι ώστε να μην τα έχουμε δύο φορές.

χρησιμοποιώντας την read_excel ανοίχουμε τα σύνολα δεδομένων σε μορφή DataFrame της pandas και μέσω της συνάρτησης που δημιουργήσαμε παραπάνω, διορθώνουμε τα προβληματικά σύνολα δεδομένων

Παρατηρείται ότι η ίδια στήλη έχει διαφορετική ονομασία στο σύνολο του 2000-2012 έτσι την αλλάζουμε χρησιμοποιώντας την rename για να ταιριάζει με όλα τα άλλα σύνολα.

Προσθέτουμε όλα τα σύνολα δεδομένων έτσι ώστε να πάρουμε ένα σύνολο δεδομένων με τις πυρκαγιές του 2000 εως και του 2021

ενδιαφερόμαστε μόνο για τον νομό της Αττικής και άρα μέσω ενός φίλτρου στην στήλη Νομός του συνόλου δεδομένων, κρατάμε μόνο τα δεδομένα που έχουν Νομός=ΑΤΤΙΚΗΣ

χρησιμοποιώντας την drop_duplicates πετάμε τις επαναλήψεις ημερομηνιών λόγω συνέχειας των ίδιων πυρκαγίων,και έτσι λαμβάνουμε ένα σύνολο δεδομένων με τον πραγματικό αριθμό πυρκαγιών που συνέβησαν.

πετάμε τα κενά στοιχεία στοιχεία στην στήλη "Περιοχή" χρησιμοποιώντας την dropna() της pandas και αποθηκεύουμε το dataframe στην μεταβλητή location

χρησιμοποιώντας την value_counts() της pandas η οποία επιστρέφει τον αριθμό που συναντάται το κάθε στοιχείο, αποθηκεύουμε σε ένα λεξικό την περιοχή και τον αριθμό φορών που την συναντάμε στο σύνολο. Έτσι καταγράφεται ο αριθμός που συναντάται κάθε περιοχή σε διαφορετική ημερομηνία το οποίο αντιστοιχεί στο πόσες φορές έχει αρπάξει πυρκαγία σε αυτήν την περιοχή.

Αφαιρείται το στοιχείο '-' από το λεξικό και εκτυπώνονται τα αποτελέσματα.

Δημιουργούμε ένα dataframe αυτής του λεξικού του οποίου αφαιρούμε τις ονομασίες των στηλών για λόγους ομορφιάς και αφαιρούμε το στοιχείο '-' χρησιμοποιώντας αρνητικό φίλτρο.
Στην συνέχεια αποθηκεύουμε αυτό το σύνολο δεδομένων ως "fire_counts.xlsx "

Στην συνέχεια, σκοπός μας είναι να φτιάξουμε έναν χάρτη ο οποίος να απεικονίζει έναν κύκλο γύρω από κάθε περιοχή, ο οποίος ανάλογα με το χρώμα του θα απεικονίζει το πόσες φορές έχει καεί αυτή η περιοχή. Το χρώμα του κάθε κύκλου θα έχει εύρος από το μπλέ έως το κόκκινο.

Για να γίνει αυτό θα πρέπει κάθε περιοχή να υπάρχει μία φορά στο σύνολο δεδομένων έτσι ώστε να αποφύγουμε τις περιττές επαναλήψεις. Συνεπώς πετάμε τις επαναλήψεις των περιοχών χρησιμοποιώντας την drop_duplicates και αποθηκέυουμε το σύνολο δεδομένων στο df_map.

Αρχικά για να δημιουργηθούν αυτοί οι κύκλοι θα πρέπει να καθορίζεται ένα μέτρο το οποίο θα τους δίνει το χρώμα. Ξέρουμε ότι αυτό το μέτρο είναι ο αριθμός πυρκαγιών, έτσι για να το μετατρέψουμε σε έυρος από το 0 εώς το 1 διαιρούμε με το μέγιστο τους αριθμούς των φορών που έχει καεί κάθε περιοχή και αποθηκεύουμε τα αποτελέσματα στο λεξικό fire_counts_normalized.

Έχοντας τώρα δημιουργήσει το μέτρο αυτό, το προσθέτουμε στο σύνολο δεδομένων df_map και στην συνέχεια αποθηκεύουμε το σύνολο αυτό στο αρχείο fires.xlsx

Στην συνέχεια απαντάμε στα ερευνητικά ερωτήματα. 

Για να βρούμε την περιοχή με τις περισσότερες πυρκαγιές κατασκευάζουμε μία συνάρτηση lamda η οποία επιστρέφει το μέγιστο ενός λεξικού βάσει την τιμή του και όχι το κλείδι του και την εφαρμόζουμε στο λεξικό fire_counts

για να βρούμε το σύνολο των καμένων εκτάσεων απλώς βρίσκουμε το μέγεθος του fire_counts

για να βρούμε πόσες πυρκαγίες έχουν συμβεί συνολικά σε όλη την Ελλάδα κατά την διάρκεια 2000-2021, παίρνουμε το αρχικό σύνολο, πετάμε τις επαναλήψεις ημερομηνιών και βρίσκουμε το μέγεθος 

για να βρούμε τον συνολικό αριθμό πυρκαγιών στην Αττική, βρίσκουμε το μέγεθος του df_attiki αφού του αφαιρέσουμε τις επαναλήωεις ημεομηνιών.

για να βρούμε τον συνολικό αριθμό καμμένων στρεμμάτων γεωργικών εκτάσεων στην Αττική, παίρνουμε το άθροισμα της στήλης 'Γεωργικές Εκτάσεις ' στο σύνολο df_attiki_unique

για να βρούμε τον συνολικό αριθμό καμμένων δασών στην Αττική βρίσκουμε τα δάση που δεν έχουν καεί, τα αφαιρούμε χρησιμοποιώντας ένα φίλτρο και έπειτα βρίσκουμε το μέγεθος του συνόλου

για να βρούμε τον συνόλικο αριθμό καμμένων γεωργικών εκτάσεων εφαρμόζουμε το ίδιο με παραπάνω. 

Θέλουμε να βρούμε τον χρόνο κατάσβεσης για κάθε συμβάν. 
Αρχικά δημιουργούμε ένα σύνολο που περιέχει μόνο την περιοχή και τις ημερομηνίες και τις ώρες έναρξης και κατάσβεσης της πυρκαγιάς

έπειτα αφαιρούμε προβληματικές ημερομηνίες με την εξής μεθοδολογία : 
κατασκευάζουμε μία κανονική έκφραση η οποία εκπροσωπεί το πως θα έπρεπε να είναι μία σωστή ημερομηνία. Οι ημερομηνίες που δεν ταιριάζουν με αυτήν την κανονική έκφραση αποθηκεύονται σε μία λίστα drop_list και στην συνέχεια αφαιρούνται από το σύνολο χρησιμοποιώντας την συνάρτηση drop

στην συνέχεια παίρνουμε κάθε στήλη ημερομηνίας ή ώρας και την μετατρέπουμε σε αντικείμενο datetime της pandas έτσι ώστε να μπορούμε να κάνουμε πράξεις μεταξύ των ημερομηνιών και των ωρών.

Αφού έχουμε μετατρέψει τα στοιχεία σε αντικείμενα datetime 
βρίσκουμε την διαφορά της ημερομηνίας έναρξης με την ημερομηνία κατάσβεσης για κάθε συμβάν σε ώρες. 

μετά βρίσκουμε την διαφορά των ώρων έναρξης και κατάσβεσης για κάθε συμβάν σε  ώρες 

στην συνέχεια άν έχει υπάρξει διαφορά μεταξύ των ωρας έναρξης και ωρας κατάσβεσης τότε προστίθεται στην διαφορά ημερομήνιων έναρξής και κατάσβεσης αλλίως δεν προστίθεται. 

Σε αυτό το σύνολο δεδομένων δημιουργούνται κάποια κενά στοιχεία τα οποία τα αφαιρούμε χρησιμοποιώντας την dropna()

έπειτα εκτυπώνουμε το σύνολο και στην συνέχεια το αποθηκεύουμε με ονομασία fire_time.xlsx

Επεξήγηση του coor.py 

Για να απεικονίσουμε κάθε περιοχή στον χάρτη θα χρειαστούμε συντεταγμένες (latitude, longitude). Θα χρησιμοποιήσουμε τον geocoder Nominatim της βιβλιοθήκης geopy της python έτσι ώστε να γίνει λήψη των συντεταγμένων. 

Αρχικά κατασκευάζουμε μία συνάρτηση η οποία αρχικοποιεί έναν αντικείμενο Nominatim και στην συνέχεια, με είσοδο μία λίστα από περιοχές η συνάρτηση αυτή δημιουργεί έναν βρόγχο ο οποίος διατρέχει όλες τις περιοχές, ελέγχει αν υπάρχουν συντεταγμένες για την ονομασία αυτής της περιοχής και αν υπάρχουν τις αποθηκεύει ως πλειάδα στην λίστα coordinates αλλίως αποθηκεύει None. Τέλος αυτή η συνάρτηση επιστρέφει τις συντεταγμένες που βρέθηκαν.

διαβάζεται το αρχείο fires.xlsx από το οποίο λαμβάνεται η λίστα με τις περιοχές, και χρησιμοποιώντας την παραπάνω συνάρτηση επιστρέφονται οι συντεταγμένες των περιοχών (εαν υπάρχουν) και αποθηκεύονται στην λίστα coor

χρησιμοποιώντας έναν βρόγχο διατρέχεται η λίστα coor και αν η πλειάδα δεν είναι None τότε προστίθεται το πρώτο της στοιχείο στην στήλη X-ENGAGE και το δεύτερο στοιχείο στην στήλη Y-ENGAGE

στην συνέχεια αφαιρούνται τα κενά δεδομένα από το σύνολο 
και το σύνολο αποθηκεύεται ως fires_coor.xlsx

Επεξήγηση του make_map.py 

Σε αυτό το πρόγραμμα Δημιουργείται η ιστοσελίδα που θέλουμε να φτιάξουμε. 

Θα χρειαστούμε την βιβλιοθήκη streamlit για να φτιαχτεί η ιστοσελίδα , την βιβλιοθήκη folium για να φτιαχτεί ο χάρτης, την βιβλιοθήκη pandas για να επεξεργαστούμε τα δεδομένα και να τα παρουσιάσουμε,  την βιβλιοθήκη numpy για μαθηματικές πράξεις και την συνάρτηση st_folium την βιβλιοθήκη streamlit_folium για να παρουσιαστεί ο χάρτης στην ιστοσελίδα.

αρχικά διαβάζεται το fires_coor.xlsx χρησιμοποιώντας την pandas. Στην συνέχεια οι στήλες X-ENGAGE, Y-ENGAGE και intensity μετατρέπονται στις λίστες lon, lat, weight αντίστοιχα. 

Έπειτα καθαρίζονται κάποια δεδομένα στην λίστα weight. 
Στην συνέχεια τα στοιχεία από τις λίστες αυτές συνδυάζονται ως πλειάδες του τύπου (lon[i], lat[i], weight[i]) σε μία λίστα με ονομασία data_list 

Δημιουργείται ο χάρτης με κέντρο το πρώτο στοιχείο των συντεταγμένων.

Στην συνέχεια πρέπει να ορίσουμε τα χρώματα ανάλογα με το εύρος του βάρους έντασης κάθε περιοχής. Αυτό το κάνουμε χρησιμοποιώντας ποσοστιμόρια με την συνάρτηση numpy.quantile(). Έτσι χωρίζουμε την λίστα weight σε 5 κομμάτια, άν το βάρος της εκάστοτε περιοχής βρίσκεται στο 1ο κομμάτι, τότε θα πάρει το χρώμα μπλε, αν βρίσκεται στο 2ο, τότε θα πάρει το χρώμα κίτρινο, αν βρίσκεται στο 3ο, τότε θα πάρει το χρώμα πορτοκαλί, αν βρίσκεται στο 4ο, τότε θα πάρει το χρωμα κόκκινο και αν βρίσκεται στο  5ο, τότε θα πάρει το χρώμα μπορντό.

Χρησιμοποιώντας την παραπάνω λογική κατασκευάζουμε έναν βρόγχο ο οποίος διατρέχει την λίστα data_list με τις συντεταγμένες και τα βάρη τους και τους θέτει το ανάλογο χρώμα.
Στην συνέχεια χρησιμοποιώντας την μέθοδο Circle() της folium κατασκευάζονται κύκλοι στις συντεταγμένες των περιοχών με το αντίστοιχο χρώμα και προστίθενται στον χάρτη.

Έπειτα χρησιμοποιώντας την συνάρτηση write της streamlit γράφουμε τα ανάλογα κείμενα, προσθέτουμε τίτλους και σύνολα στην ιστοσελίδα μας, με την image() προσθέτουμε εικόνες και με την st_folium() προσθέτουμε τον χάρτη.


